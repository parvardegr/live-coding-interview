# Application
spring.application.name=interview

topic.name=interview
message.count=5000

# Kafka
spring.kafka.consumer.group-id=interview
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=ir.metrix.interview

#### performance tuning
# Inter process communication simulation delay, just to get the performance results faster(testing purposes).
operation.delay=1000
# I've done the partitioning based on the userId's hash(consistent hashing).
# Each partition can be processed in parallel by a dedicated thread.
# This maximizes throughput and ensures that the processing load is evenly distributed across available threads.
# Right now, we have 2 concurrent consumers(check MessageConsumer.java), so we can process data in 2 partitions with 2 dedicated active consumers.
partition.count=2
# Batching allows multiple messages to be sent together in a single network request.
# The 16KB batch size is large enough to reduce the network load, also small enough to process multiple batches concurrently without running into memory issues.
# Estimation:
#   each message size = ~35
#   16,384 / 35 = 468 messages per batch
spring.kafka.producer.batch-size=16384
# This parameter show that how much record on each poll will be requested. (from the consumer point of view)
# This has been set based on the estimation for producer's batch.size.
# Alignment of max.poll.records with batch.size leads to a more consistent producer/consumer behaviour.
# It will reduce the end-to-end latency because consumer can process data as soon as it's available.
# In the consumers(check MessageConsumer.java) the batch option has been set to `true` to enable batch processing
spring.kafka.consumer.max-poll-records=468
# By having the replication factor of 2, each partition has a leader which is responsible for its read/write operations.
# This setup ensures that the load is balanced between available brokers.
# Also in case of failure of one replica in the cluster, data can be accessed by the other replica.
# If one of the replicas goes down, other one can continue processing the data(without redundancy).
# After that the application goes to the normal-state(both nodes are healthy), Kafka trigger a re-election to balance the load between replicas.
replica.factor=2
# How many acknowledgments producer need to have to consider a message successful.
# This is a trade-off between message durability and producer performance.
spring.kafka.producer.acks=1